<?xml version="1.0" encoding="UTF-8"?>
<config>

    <!-- database-related configuration -->
    <db>
        <!-- fully qualified class name of the JDBC driver to use.
             to use a different driver, you must specify the jar when running
             this application using -libjars /path/to/mydriver.jar
             default: "com.mysql.jdbc.Driver" (included, no need to add to
             -libjars) -->
        <driverclass>com.mysql.jdbc.Driver</driverclass>

        <!-- string for the "scheme" part of a jdbc connection string,
             (e.g. scheme://...) default: "jdbc:mysql" (for the included
             driver) -->
        <scheme>jdbc:mysql</scheme>

        <!-- database host (default: localhost) -->
        <host>localhost</host>

        <!-- database port (default: 3306) -->
        <port>3306</port>

        <!-- name of database that contains output table -->
        <database>mydatabase</database>

        <!-- db username -->
        <user>myusername</user>

        <!-- db password -->
        <password>mypassword</password>

        <!-- name of output table, which must exist and have exactly five
             columns, arbitrarily named, but capable of storing types in the
             following order:
                 String (for PMID)
                 String (for Concept1 GeneID/CUI)
                 Integer (for Sentence ID of Concept1)
                 String (for Concept2 GeneID/CUI)
                 Integer (for Sentence ID of Concept2) -->
        <tablename>CONCEPT_AGGREGATE</tablename>
    </db>

    <!-- hadoop-related configuration -->
    <hadoop>

        <!-- defines whether or not output should be written to database rather
             rather than to an HDFS file (true here requires "db" element
             above, false here requires outputdir in this ["hadoop"] element)
             default: false -->
        <dboutput>false</dboutput>

        <!-- name of the MapReduce job to be submitted -->
        <jobname>concept-pair-generator</jobname>

        <!-- override the framework-determined number of reducers, since each
             reducer will create its own connection to the database and batch
             insert all results in a transaction -->
        <numreducers>32</numreducers>

        <!-- comma-separated list of HDFS input paths to process -->
        <inputdirs>/input</inputdirs>

        <!-- hdfs path to directory to store output file (ignored if dboutput
             is true) -->
        <outputdir>/output</outputdir>

        <!-- hdfs path to the pair filter directory, which includes entries for
             all permissible pairs of concepts. the expected directory format is
             one created by org.apache.hadoop.io.SetFile.Writer with keyClass
             org.apache.hadoop.io.Text. the Text value must have the following
             format:
                 concept1|concept2
             That is, all lowercase, with concept names sorted lexographically,
             separated by the pipe "|" character.
             (default: accept all pairs) -->
        <pairfilterdir>semmed-pair-filter.set</pairfilterdir>
    </hadoop>
</config>
